{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_with_neutral(text, model, tokenizer, alpha=1.5, neutral_threshold=0.1):\n",
    "    model_device = next(model.parameters()).device\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(model_device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.softmax(logits, dim=1).squeeze().tolist()\n",
    "\n",
    "    neutral_score = 1 - abs(probs[0] - 0.5) ** alpha - abs(probs[2] - 0.5) ** alpha\n",
    "    if neutral_score > (1 - neutral_threshold):\n",
    "        return 1\n",
    "    return int(torch.argmax(torch.tensor(probs)))\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce_loss = self.ce(logits, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[targets]\n",
    "            focal_loss = alpha_t * (1 - pt) ** self.gamma * ce_loss\n",
    "        else:\n",
    "            focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"clasificador_analisis/clasificador/datasets_originales/tonos_dataset.xlsx\")\n",
    "df = df.rename(columns={\"Mensaje\": \"text\", \"Etiqueta\": \"label\"})\n",
    "etiqueta_map = {\"Negativo\": 0, \"Neutro\": 1, \"Positivo\": 2}\n",
    "df[\"label\"] = df[\"label\"].map(etiqueta_map)\n",
    "df = df.dropna()\n",
    "\n",
    "model_name = \"VerificadoProfesional/SaBERT-Spanish-Sentiment-Analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_dir = \"clasificador_analisis/clasificador/clasificador_tono/classweights_focalloss/comparativa\"\n",
    "\n",
    "class_counts = df[\"label\"].value_counts().sort_index()\n",
    "class_weights = 1. / class_counts\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "alpha = torch.tensor(class_weights.tolist(), dtype=torch.float)\n",
    "\n",
    "epoch_values = range(3, 4)\n",
    "gamma_values = np.arange(0.3, 0.31, 0.1)\n",
    "\n",
    "mejor_accuracy = 0\n",
    "mejor_comb = \"\"\n",
    "mejor_f1_equilibrio = float('inf')\n",
    "mejor_result_path = \"\"\n",
    "\n",
    "accuracy_por_comb = defaultdict(list)\n",
    "recall_dist_por_comb = defaultdict(lambda: {\"neu-neg\": [], \"neu-pos\": [], \"neg-pos\": []})\n",
    "top_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "dataset = Dataset.from_pandas(df_balanced)\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "train_valid_split = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_valid_split[\"train\"]\n",
    "valid_dataset = train_valid_split[\"test\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x: tokenizer(x[\"text\"], padding=\"max_length\", truncation=True, max_length=128), batched=True)\n",
    "valid_dataset = valid_dataset.map(lambda x: tokenizer(x[\"text\"], padding=\"max_length\", truncation=True, max_length=128), batched=True)\n",
    "test_dataset = test_dataset.map(lambda x: tokenizer(x[\"text\"], padding=\"max_length\", truncation=True, max_length=128), batched=True)\n",
    "\n",
    "for num_epochs in epoch_values:\n",
    "    for gamma in gamma_values:\n",
    "        print(f\"\\nüéØ√âpocas: {num_epochs} | Gamma: {gamma}\")\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3, ignore_mismatched_sizes=True)\n",
    "\n",
    "        def compute_loss(model, inputs, return_outputs=False):\n",
    "            labels = inputs.get(\"labels\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.get(\"logits\")\n",
    "            loss_fn = FocalLoss(alpha=alpha.to(logits.device), gamma=gamma)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "        model.compute_loss = compute_loss\n",
    "\n",
    "        path = f\"{base_dir}/ep_{num_epochs}_gamma_{gamma:.2f}\"\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=path,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=3e-5,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=16,\n",
    "            num_train_epochs=num_epochs,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir=\"./logs\",\n",
    "            logging_steps=10,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=valid_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        df_test = test_dataset.to_pandas()\n",
    "        preds = df_test[\"text\"].apply(lambda x: predict_sentiment_with_neutral(x, model, tokenizer))\n",
    "        df_test[\"label_predicted\"] = preds\n",
    "\n",
    "        y_true = df_test[\"label\"]\n",
    "        y_pred = df_test[\"label_predicted\"]\n",
    "\n",
    "        print(\"\\nüìä MATRIZ DE CONFUSI√ìN:\")\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "        print(\"\\nüìà CLASSIFICATION REPORT:\")\n",
    "        print(classification_report(y_true, y_pred, target_names=[\"Negativo\", \"Neutro\", \"Positivo\"]))\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        report = classification_report(y_true, y_pred, target_names=[\"Negativo\", \"Neutro\", \"Positivo\"], output_dict=True)\n",
    "        recall_neg = report[\"Negativo\"][\"recall\"]\n",
    "        recall_neu = report[\"Neutro\"][\"recall\"]\n",
    "        recall_pos = report[\"Positivo\"][\"recall\"]\n",
    "\n",
    "        comb_key = f\"ep{num_epochs}_g{gamma:.2f}\"\n",
    "        accuracy_por_comb[comb_key].append(accuracy)\n",
    "        recall_dist_por_comb[comb_key][\"neu-neg\"].append(abs(recall_neu - recall_neg) * 100)\n",
    "        recall_dist_por_comb[comb_key][\"neu-pos\"].append(abs(recall_neu - recall_pos) * 100)\n",
    "        recall_dist_por_comb[comb_key][\"neg-pos\"].append(abs(recall_neg - recall_pos) * 100)\n",
    "\n",
    "        f1s = [f1_score(y_true, y_pred, labels=[i], average=\"macro\") for i in range(3)]\n",
    "        f1_eq = np.std(f1s)\n",
    "\n",
    "        top_results.append({\n",
    "            \"combinacion\": comb_key,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1_eq\": f1_eq,\n",
    "            \"ruta\": path\n",
    "        })\n",
    "\n",
    "        es_mejor = (accuracy > mejor_accuracy) or (accuracy == mejor_accuracy and f1_eq < mejor_f1_equilibrio)\n",
    "\n",
    "        if es_mejor:\n",
    "            anterior_path = mejor_result_path\n",
    "            mejor_accuracy = accuracy\n",
    "            mejor_comb = comb_key\n",
    "            mejor_result_path = path\n",
    "            mejor_f1_equilibrio = f1_eq\n",
    "\n",
    "            if anterior_path and anterior_path != path and os.path.exists(anterior_path):\n",
    "                shutil.rmtree(anterior_path)\n",
    "                print(f\"üóëÔ∏è Eliminado modelo anterior: {anterior_path}\")\n",
    "\n",
    "            df_train = train_dataset.to_pandas()\n",
    "            df_valid = valid_dataset.to_pandas()\n",
    "            df_test_export = test_dataset.to_pandas()\n",
    "\n",
    "            df_train.to_excel(\"clasificador_analisis/clasificador/clasificador_tono/classweights_focalloss/mejor_train.xlsx\", index=False)\n",
    "            df_valid.to_excel(\"clasificador_analisis/clasificador/clasificador_tono/classweights_focalloss/mejor_valid.xlsx\", index=False)\n",
    "            df_test_export.to_excel(\"clasificador_analisis/clasificador/clasificador_tono/classweights_focalloss/mejor_test.xlsx\", index=False)\n",
    "\n",
    "            model.save_pretrained(f\"{path}/modelo_final\")\n",
    "            tokenizer.save_pretrained(f\"{path}/modelo_final\")\n",
    "\n",
    "            print(f\"üíæ Guardado nuevo mejor modelo: {comb_key} | Accuracy: {accuracy} | Path: {path}\")\n",
    "        else:\n",
    "            if path != mejor_result_path and os.path.exists(path):\n",
    "                shutil.rmtree(path)\n",
    "                print(f\"‚õî Borrado modelo descartado: {path}\")\n",
    "\n",
    "print(f\"\\nüèÅ Mejor combinaci√≥n final ‚Üí {mejor_comb} | Accuracy: {mejor_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"clasificador_analisis/clasificador/clasificador_tono/classweights_focalloss/comparativa/ep_3_gamma_0.30/modelo_final\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "def predict_sentiment_with_neutral_alpha_thresh(text, model, tokenizer, alpha, neutral_threshold):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(next(model.parameters()).device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.softmax(logits, dim=1).squeeze()\n",
    "    neutral_score = 1 - (abs(probs[0] - 0.5) ** alpha + abs(probs[2] - 0.5) ** alpha)\n",
    "    if neutral_score > (1 - neutral_threshold):\n",
    "        return 1\n",
    "    else:\n",
    "        return int(torch.argmax(probs))\n",
    "\n",
    "df = pd.read_excel(\"clasificador_analisis/clasificador/clasificador_tono/classweights_focalloss/mejor_test.xlsx\")\n",
    "df = df.rename(columns={\"text\": \"text\", \"label\": \"label_manual_num\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = np.arange(1.0, 1.1, 0.1)\n",
    "threshold_values = np.arange(0.1, 0.3, 0.1)\n",
    "\n",
    "best_acc = 0\n",
    "best_combo = None\n",
    "best_preds = None\n",
    "results = []\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    for threshold in threshold_values:\n",
    "        print(f\"üîç Probando Alpha={alpha:.2f}, Threshold={threshold:.2f}\")\n",
    "        preds = df[\"text\"].apply(lambda x: predict_sentiment_with_neutral_alpha_thresh(x, model, tokenizer, alpha, threshold))\n",
    "        acc = accuracy_score(df[\"label_manual_num\"], preds)\n",
    "\n",
    "        results.append({\n",
    "            \"alpha\": round(alpha, 2),\n",
    "            \"threshold\": round(threshold, 2),\n",
    "            \"accuracy\": acc\n",
    "        })\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_combo = (round(alpha, 2), round(threshold, 2))\n",
    "            best_preds = preds\n",
    "\n",
    "            print(f\"\\nüî• Nueva mejor combinaci√≥n encontrada: Alpha={alpha:.2f}, Threshold={threshold:.2f}, Accuracy={acc:.4f}\")\n",
    "            print(\"\\nüìä MATRIZ DE CONFUSI√ìN:\")\n",
    "            print(confusion_matrix(df[\"label_manual_num\"], best_preds))\n",
    "            print(\"\\nüìà CLASSIFICATION REPORT:\")\n",
    "            print(classification_report(\n",
    "                df[\"label_manual_num\"],\n",
    "                best_preds,\n",
    "                target_names=[\"Negativo\", \"Neutro\", \"Positivo\"],\n",
    "                digits=5\n",
    "            ))\n",
    "\n",
    "print(f\"\\nüèÜ Mejor combinaci√≥n final ‚Üí Alpha={best_combo[0]}, Threshold={best_combo[1]}, Accuracy={best_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
