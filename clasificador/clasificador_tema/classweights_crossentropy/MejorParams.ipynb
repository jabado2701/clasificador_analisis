{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be749452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a017d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"clasificador_analisis/clasificador/basico/tonos_dataset.xlsx\")\n",
    "df = df.rename(columns={\"Mensaje\": \"text\", \"Etiqueta\": \"label\"})\n",
    "\n",
    "etiqueta_map = {\n",
    "    \"Gestión Pública e Instituciones\": 0,\n",
    "    \"Economía, Empresa, Empleo e Infraestructuras\": 1,\n",
    "    \"Sociedad, Igualdad y Derechos\": 2,\n",
    "    \"Otros\": 3\n",
    "}\n",
    "target_names = list(etiqueta_map.keys())\n",
    "\n",
    "df[\"label\"] = df[\"label\"].map(etiqueta_map)\n",
    "df = df.dropna()\n",
    "\n",
    "model_name = \"VerificadoProfesional/SaBERT-Spanish-Sentiment-Analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_dir = \"clasificador_analisis/clasificador/clasificador_tema/classweights_crossentropy/comparativa\"\n",
    "\n",
    "class_counts = df[\"label\"].value_counts().sort_index()\n",
    "class_weights = 1. / class_counts\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "alpha = torch.tensor(class_weights.tolist(), dtype=torch.float)\n",
    "\n",
    "epoch_values = range(3, 7)  \n",
    "\n",
    "mejor_accuracy = 0\n",
    "mejor_comb = \"\"\n",
    "mejor_f1_equilibrio = float('inf')\n",
    "mejor_result_path = \"\"\n",
    "mejor_recall = 0\n",
    "mejor_recall_std = float('inf')\n",
    "\n",
    "accuracy_por_comb = defaultdict(list)\n",
    "top_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, inputs, return_outputs=False):\n",
    "    labels = inputs.get(\"labels\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.get(\"logits\")\n",
    "\n",
    "    loss_fn = CrossEntropyLoss(weight=alpha.to(logits.device))\n",
    "    loss = loss_fn(logits, labels)\n",
    "\n",
    "    return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df.sample(frac=1, random_state=43).reset_index(drop=True)\n",
    "dataset = Dataset.from_pandas(df_balanced).shuffle(seed=43)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "train_valid_split = dataset[\"train\"].train_test_split(test_size=0.2, seed=43)\n",
    "train_dataset = train_valid_split[\"train\"]\n",
    "valid_dataset = train_valid_split[\"test\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "tokenize = lambda x: tokenizer(x[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "valid_dataset = valid_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "for num_epochs in epoch_values:\n",
    "    comb_key = f\"ep{num_epochs}\"\n",
    "    path = f\"{base_dir}/{comb_key}\"\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4, ignore_mismatched_sizes=True)\n",
    "    model.compute_loss = compute_loss\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=path,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=3e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=num_epochs,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=10,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    df_test = test_dataset.to_pandas()\n",
    "    inputs = tokenizer(df_test[\"text\"].tolist(), return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "\n",
    "    y_true = df_test[\"label\"]\n",
    "    y_pred = preds\n",
    "\n",
    "    print(\"\\n📊 MATRIZ DE CONFUSIÓN:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n📈 CLASSIFICATION REPORT:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    recalls = [report[label][\"recall\"] for label in target_names]\n",
    "    recall_macro = np.mean(recalls)\n",
    "    recall_std = np.std(recalls)\n",
    "\n",
    "    accuracy_por_comb[comb_key].append(accuracy)\n",
    "\n",
    "    top_results.append({\n",
    "        \"combinacion\": comb_key,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"recall_std\": recall_std,\n",
    "        \"ruta\": path\n",
    "    })\n",
    "\n",
    "    es_mejor = (\n",
    "        (accuracy > mejor_accuracy and recall_macro >= mejor_recall) or\n",
    "        (accuracy == mejor_accuracy and recall_macro > mejor_recall) or\n",
    "        (accuracy == mejor_accuracy and recall_macro == mejor_recall and recall_std < mejor_recall_std)\n",
    "    )\n",
    "\n",
    "    if es_mejor:\n",
    "        anterior_path = mejor_result_path\n",
    "        mejor_accuracy = accuracy\n",
    "        mejor_comb = comb_key\n",
    "        mejor_result_path = path\n",
    "        mejor_recall = recall_macro\n",
    "        mejor_recall_std = recall_std\n",
    "\n",
    "        if anterior_path and anterior_path != path and os.path.exists(anterior_path):\n",
    "            shutil.rmtree(anterior_path)\n",
    "            print(f\"🗑️ Eliminado modelo anterior: {anterior_path}\")\n",
    "\n",
    "        df_train = train_dataset.to_pandas()\n",
    "        df_valid = valid_dataset.to_pandas()\n",
    "        df_test_export = test_dataset.to_pandas()\n",
    "\n",
    "        df_train.to_excel(\"clasificador_analisis/clasificador/clasificador_tema/classweights_crossentropy/mejor_train.xlsx\", index=False)\n",
    "        df_valid.to_excel(\"clasificador_analisis/clasificador/clasificador_tema/classweights_crossentropy/mejor_valid.xlsx\", index=False)\n",
    "        df_test_export.to_excel(\"clasificador_analisis/clasificador/clasificador_tema/classweights_crossentropy/mejor_test.xlsx\", index=False)\n",
    "\n",
    "        model.save_pretrained(f\"{path}/modelo_final\")\n",
    "        tokenizer.save_pretrained(f\"{path}/modelo_final\")\n",
    "\n",
    "        print(f\"💾 Guardado nuevo mejor modelo: {comb_key} | Accuracy: {accuracy:.4f} | Recall: {recall_macro:.4f} | Path: {path}\")\n",
    "    else:\n",
    "        if path != mejor_result_path and os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "            print(f\"⛔ Borrado modelo descartado: {path}\")\n",
    "\n",
    "print(f\"\\n🏁 Mejor combinación final → {mejor_comb} | Accuracy: {mejor_accuracy:.4f} | Recall: {mejor_recall:.4f} | STD: {mejor_recall_std:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
