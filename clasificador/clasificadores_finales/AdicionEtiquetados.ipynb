{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1c2cbf",
   "metadata": {},
   "source": [
    "## Funciones comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d4b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def cargar_excel_varias_hojas(ruta):\n",
    "    hojas = pd.read_excel(ruta, sheet_name=None)\n",
    "    return hojas[\"Posts\"], hojas[\"Metadata\"], hojas[\"Comentarios\"]\n",
    "\n",
    "def eliminar_columna_si_existe(df, columna):\n",
    "    return df.drop(columns=[columna]) if columna in df.columns else df\n",
    "\n",
    "def eliminar_duplicados_por_columna(df, columna, etiqueta=\"dataset\"):\n",
    "    conteo = df[columna].value_counts()\n",
    "    duplicados = conteo[conteo > 1]\n",
    "    if not duplicados.empty:\n",
    "        print(f\"\\n‚ö†Ô∏è Duplicados detectados en {etiqueta}:\")\n",
    "        print(duplicados)\n",
    "        df = df.drop_duplicates(subset=columna, keep=\"first\")\n",
    "        print(\"‚úÖ Duplicados eliminados.\")\n",
    "    return df\n",
    "\n",
    "def verificar_coincidencias(mensajes_manual, mensajes_general, etiqueta=\"Mensajes\"):\n",
    "    coincidencias = mensajes_manual & mensajes_general\n",
    "    no_encontrados = mensajes_manual - mensajes_general\n",
    "    print(f\"\\n‚úÖ {etiqueta} etiquetados manualmente: {len(mensajes_manual)}\")\n",
    "    print(f\"‚úÖ {etiqueta} encontrados en Posts: {len(coincidencias)}\")\n",
    "    print(f\"‚ùå {etiqueta} NO encontrados: {len(no_encontrados)}\")\n",
    "    return coincidencias, no_encontrados\n",
    "\n",
    "def guardar_excel_con_hojas(ruta, df_metadata, df_posts, df_comentarios):\n",
    "    with pd.ExcelWriter(ruta, engine=\"openpyxl\") as writer:\n",
    "        df_metadata.to_excel(writer, sheet_name=\"Metadata\", index=False)\n",
    "        df_posts.to_excel(writer, sheet_name=\"Posts\", index=False)\n",
    "        df_comentarios.to_excel(writer, sheet_name=\"Comentarios\", index=False)\n",
    "\n",
    "def verificar_duplicados_por_merge(df, columna_id, filas_antes, nombre_archivo):\n",
    "    filas_despues = len(df)\n",
    "    if filas_despues > filas_antes:\n",
    "        print(f\"‚ö†Ô∏è Se han a√±adido {filas_despues - filas_antes} filas tras el merge. Posible duplicaci√≥n.\")\n",
    "        df_dup = df[df.duplicated(subset=[columna_id], keep=False)]\n",
    "        if not df_dup.empty:\n",
    "            df_dup.to_excel(nombre_archivo, index=False)\n",
    "            print(f\"üìù Posibles duplicados exportados a {nombre_archivo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91380d6",
   "metadata": {},
   "source": [
    "## Tema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148a056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Duplicados detectados en df_tematica:\n",
      "Invasi√≥n \\n Invasi√≥n \\n Invasi√≥n\\n Invasi√≥n\\n Invasi√≥n\\n Invasi√≥n\\n Invasi√≥n\\n Invasi√≥n\\n Invasi√≥n\\n Invasi√≥n    2\n",
      "Name: Contenido_Traducido, dtype: int64\n",
      "‚úÖ Duplicados eliminados.\n",
      "\n",
      "‚úÖ Mensajes etiquetados manualmente: 918\n",
      "‚úÖ Mensajes encontrados en Posts: 918\n",
      "‚ùå Mensajes NO encontrados: 0\n",
      "\n",
      "üîç Enlaces nuevos (no estaban en el original): 0\n"
     ]
    }
   ],
   "source": [
    "ruta_base = \"clasificador_analisis/clasificador/datasets_originales/\"\n",
    "ruta_excel_general = ruta_base + \"politicos_final.xlsx\"\n",
    "ruta_excel_tematica = ruta_base + \"temas_dataset.xlsx\"\n",
    "ruta_salida = ruta_base + \"politicos_tema_actualizado.xlsx\"\n",
    "\n",
    "df_posts, df_metadata, df_comentarios = cargar_excel_varias_hojas(ruta_excel_general)\n",
    "df_posts_original = df_posts.copy()\n",
    "\n",
    "df_tematica = pd.read_excel(ruta_excel_tematica)\n",
    "df_tematica = df_tematica.rename(columns={\"Mensaje\": \"Contenido_Traducido\", \"Etiqueta\": \"Tema\"})\n",
    "df_tematica = eliminar_duplicados_por_columna(df_tematica, \"Contenido_Traducido\", etiqueta=\"df_tematica\")\n",
    "df_posts = eliminar_columna_si_existe(df_posts, \"Tema\")\n",
    "\n",
    "df_posts = df_posts.merge(\n",
    "    df_tematica[[\"Contenido_Traducido\", \"Tema\"]],\n",
    "    on=\"Contenido_Traducido\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "mensajes_manual = set(df_tematica[\"Contenido_Traducido\"].dropna())\n",
    "mensajes_general = set(df_posts[\"Contenido_Traducido\"].dropna())\n",
    "coinciden, no_encontrados = verificar_coincidencias(mensajes_manual, mensajes_general, etiqueta=\"Mensajes\")\n",
    "\n",
    "if no_encontrados:\n",
    "    df_no = df_tematica[df_tematica[\"Contenido_Traducido\"].isin(no_encontrados)]\n",
    "    df_no.to_excel(ruta_base + \"mensajes_no_emparejados.xlsx\", index=False)\n",
    "\n",
    "verificar_duplicados_por_merge(\n",
    "    df_posts,\n",
    "    columna_id=\"Enlace_Post\",\n",
    "    filas_antes=len(df_posts_original),\n",
    "    nombre_archivo=ruta_base + \"posts_duplicados_por_merge.xlsx\"\n",
    ")\n",
    "\n",
    "enlaces_original = set(df_posts_original[\"Enlace_Post\"].dropna())\n",
    "enlaces_actual = set(df_posts[\"Enlace_Post\"].dropna())\n",
    "enlaces_agregados = enlaces_actual - enlaces_original\n",
    "\n",
    "print(f\"\\nüîç Enlaces nuevos (no estaban en el original): {len(enlaces_agregados)}\")\n",
    "\n",
    "if enlaces_agregados:\n",
    "    df_agregados = df_posts[df_posts[\"Enlace_Post\"].isin(enlaces_agregados)]\n",
    "    print(\"\\nüîó Enlaces agregados inesperadamente:\")\n",
    "    print(df_agregados[[\"Enlace_Post\", \"Contenido_Traducido\", \"Tema\"]].to_string(index=False))\n",
    "    df_agregados.to_excel(ruta_base + \"posts_agregados_por_merge.xlsx\", index=False)\n",
    "\n",
    "guardar_excel_con_hojas(ruta_salida, df_metadata, df_posts, df_comentarios)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56447d76",
   "metadata": {},
   "source": [
    "## Tono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73c875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Duplicados detectados en df_tono_posts:\n",
      "Invasi√≥n \\n Invasi√≥n \\n Invasi√≥n\\n Invasi√≥n\\n Invasi√≥n\\n Invasi√≥n\\n Invasi√≥n\\n Invasi√≥n\\n Invasi√≥n\\n Invasi√≥n    2\n",
      "Name: Contenido_Traducido, dtype: int64\n",
      "‚úÖ Duplicados eliminados.\n",
      "\n",
      "‚ö†Ô∏è Duplicados detectados en df_tono_comentarios:\n",
      "#Artinon                                                                                                                                                                                                                                                                                   7\n",
      "Enhorabuena                                                                                                                                                                                                                                                                                4\n",
      "DEP                                                                                                                                                                                                                                                                                        4\n",
      "En 2008 fue condenado a un a√±o y medio de c√°rcel por un delito de lesiones resultado de un ataque a golpes en perjuicio de un anciano ocurrido en 2005.  La sentencia no menciona motivaciones ni hechos previos a la agresi√≥n. Luc Andr√© Diouf fue condenado por un delito de lesiones    3\n",
      "Da gusto verte siempre \\n@estherpcamarero                                                                                                                                                                                                                                                  3\n",
      "D.E.P.                                                                                                                                                                                                                                                                                     3\n",
      "#Artinon \\n#Galicia                                                                                                                                                                                                                                                                        3\n",
      "No eres hombre de palabra:\\n\\n\"Ni limitaci√≥n de mandatos ni eliminaci√≥n de aforamientos: los partidos vuelven a traicionar a sus votantes.\"                                                                                                                                                3\n",
      "El @pp demostrando una vez m√°s que son una mala copia del \\n@PSOE\\n \\n\\nDiciendo a personas adultas como tienen que vivir sus vidas dentro de sus casas como si fuesen deficientes mentales. \\n\\nPat√©tico!                                                                                 2\n",
      "Enhorabuena!!                                                                                                                                                                                                                                                                              2\n",
      "Islas Ses                                                                                                                                                                                                                                                                                  2\n",
      "Felicidades                                                                                                                                                                                                                                                                                2\n",
      "Vamos !! \\n\\n#Artinon\\n#22 Mapobra\\n#Antrimataaminaremata                                                                                                                                                                                                                                  2\n",
      "HP ,MAL NACIDO, DESGRACIADO eres una verg√ºenza para Canarias!! L√°rgate tu y tu familia a √Åfrica!!! Clavijo Dimisi√≥n                                                                                                                                                                        2\n",
      "Name: Contenido_Traducido, dtype: int64\n",
      "‚úÖ Duplicados eliminados.\n",
      "\n",
      "‚úÖ Posts etiquetados manualmente: 918\n",
      "‚úÖ Posts encontrados en Posts: 918\n",
      "‚ùå Posts NO encontrados: 0\n",
      "\n",
      "‚úÖ Comentarios etiquetados manualmente: 1624\n",
      "‚úÖ Comentarios encontrados en Posts: 1623\n",
      "‚ùå Comentarios NO encontrados: 1\n"
     ]
    }
   ],
   "source": [
    "ruta_base = \"clasificador_analisis/clasificador/datasets_originales/\"\n",
    "ruta_excel_general = ruta_base + \"politicos_tema_actualizado.xlsx\"\n",
    "ruta_excel_tono = ruta_base + \"tonos_dataset.xlsx\"\n",
    "ruta_salida = ruta_base + \"politicos_manual_completo.xlsx\"\n",
    "\n",
    "df_posts, df_metadata, df_comentarios = cargar_excel_varias_hojas(ruta_excel_general)\n",
    "df_posts_original = df_posts.copy()\n",
    "df_comentarios_original = df_comentarios.copy()\n",
    "\n",
    "df_tono = pd.read_excel(ruta_excel_tono)\n",
    "df_tono = df_tono.rename(columns={\"Mensaje\": \"Contenido_Traducido\", \"Etiqueta\": \"Tono\"})\n",
    "\n",
    "df_tono_posts = df_tono[df_tono[\"Tipo\"] == \"Post\"]\n",
    "df_tono_comentarios = df_tono[df_tono[\"Tipo\"] == \"Comentario\"]\n",
    "\n",
    "df_tono_posts = eliminar_duplicados_por_columna(df_tono_posts, \"Contenido_Traducido\", etiqueta=\"df_tono_posts\")\n",
    "df_tono_comentarios = eliminar_duplicados_por_columna(df_tono_comentarios, \"Contenido_Traducido\", etiqueta=\"df_tono_comentarios\")\n",
    "\n",
    "df_posts = eliminar_columna_si_existe(df_posts, \"Tono\")\n",
    "df_comentarios = eliminar_columna_si_existe(df_comentarios, \"Tono\")\n",
    "\n",
    "df_posts = df_posts.merge(\n",
    "    df_tono_posts[[\"Contenido_Traducido\", \"Tono\"]],\n",
    "    on=\"Contenido_Traducido\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_comentarios = df_comentarios.merge(\n",
    "    df_tono_comentarios[[\"Contenido_Traducido\", \"Tono\"]],\n",
    "    left_on=\"Comentario_Traducido\",\n",
    "    right_on=\"Contenido_Traducido\",\n",
    "    how=\"left\"\n",
    ").drop(columns=[\"Contenido_Traducido\"])\n",
    "\n",
    "mensajes_posts = set(df_tono_posts[\"Contenido_Traducido\"].dropna())\n",
    "mensajes_general_posts = set(df_posts[\"Contenido_Traducido\"].dropna())\n",
    "coincidencias_posts, no_encontrados_posts = verificar_coincidencias(\n",
    "    mensajes_posts, mensajes_general_posts, etiqueta=\"Posts\"\n",
    ")\n",
    "\n",
    "mensajes_comentarios = set(df_tono_comentarios[\"Contenido_Traducido\"].dropna())\n",
    "mensajes_general_comentarios = set(df_comentarios[\"Comentario_Traducido\"].dropna())\n",
    "coincidencias_comentarios, no_encontrados_comentarios = verificar_coincidencias(\n",
    "    mensajes_comentarios, mensajes_general_comentarios, etiqueta=\"Comentarios\"\n",
    ")\n",
    "\n",
    "if no_encontrados_posts:\n",
    "    df_no_post = df_tono_posts[df_tono_posts[\"Contenido_Traducido\"].isin(no_encontrados_posts)]\n",
    "    df_no_post.to_excel(ruta_base + \"posts_no_emparejados_tono.xlsx\", index=False)\n",
    "\n",
    "if no_encontrados_comentarios:\n",
    "    df_no_com = df_tono_comentarios[df_tono_comentarios[\"Contenido_Traducido\"].isin(no_encontrados_comentarios)]\n",
    "    df_no_com.to_excel(ruta_base + \"comentarios_no_emparejados_tono.xlsx\", index=False)\n",
    "\n",
    "verificar_duplicados_por_merge(\n",
    "    df_posts,\n",
    "    columna_id=\"Enlace_Post\",\n",
    "    filas_antes=len(df_posts_original),\n",
    "    nombre_archivo=ruta_base + \"posts_duplicados_por_merge_tono.xlsx\"\n",
    ")\n",
    "\n",
    "verificar_duplicados_por_merge(\n",
    "    df_comentarios,\n",
    "    columna_id=\"Enlace_Comentario\",\n",
    "    filas_antes=len(df_comentarios_original),\n",
    "    nombre_archivo=ruta_base + \"comentarios_duplicados_por_merge_tono.xlsx\"\n",
    ")\n",
    "\n",
    "guardar_excel_con_hojas(ruta_salida, df_metadata, df_posts, df_comentarios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa124767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Mensajes ya etiquetados con tema: 922\n",
      "üìå Mensajes ya etiquetados con tono: 922\n",
      "üìå Comentarios ya etiquetados con tono: 1793\n"
     ]
    }
   ],
   "source": [
    "path = ruta_base + \"politicos_manual_completo.xlsx\"\n",
    "\n",
    "df_posts = pd.read_excel(path, sheet_name=\"Posts\")\n",
    "df_comentarios = pd.read_excel(path, sheet_name=\"Comentarios\")\n",
    "\n",
    "num_temas_ya_etiquetados = df_posts[\"Tema\"].notna().sum()\n",
    "num_tonos_ya_etiquetados = df_posts[\"Tono\"].notna().sum()\n",
    "comentarios_tonos_ya_etiquetados = df_comentarios[\"Tono\"].notna().sum()\n",
    "\n",
    "print(f\"üìå Mensajes ya etiquetados con tema: {num_temas_ya_etiquetados}\")\n",
    "print(f\"üìå Mensajes ya etiquetados con tono: {num_tonos_ya_etiquetados}\")\n",
    "print(f\"üìå Comentarios ya etiquetados con tono: {comentarios_tonos_ya_etiquetados}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
